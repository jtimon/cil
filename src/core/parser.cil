mode lib

import("src/core/lexer")

INFER_TYPE := "auto"

LiteralNodeType := enum {
    List: Str,
    String: Str,
    I64: I64,
    Bool: Bool,
}

// TODO support tagged unions
NodeType := enum {
    Body,
    FCall,
    Literal    : LiteralNodeType
    Identifier : Str,
    // Declaration : Declaration,
    Assignment : Str,
    // FuncDef : SFuncDef,
    // EnumDef : SEnumDef,
    // StructDef : SStructDef,
    Return,
    Throw,
    If,
    While,
    Switch,
    DefaultCase,
}

ExprArray := struct {

    push := func(mut self: ExprArray, e: Expr) {
        TODO(loc(), "Implement ExprArray.push")
    }
}

// TODO improve error: when we forget "mut" in fields: "Cannot declare 'Expr.node_type' of custom type 'NodeType'"
Expr := struct {
    mut node_type: NodeType = NodeType.Identifier
    mut params: ExprArray = ExprArray()

    new_parse := func(node_type: NodeType, token: Token, params: ExprArray) returns Expr {
        mut e := Expr()
        e.node_type = node_type
        e.params = params
        e.line = token.line
        e.col = token.col
        return e
    }
}

parse_primary_identifier := func(lexer: Lexer) returns Expr throws Str {
    t := lexer.peek()
    e := Expr()
    return e
    throw t.todo_error("parse_primary_identifier not implemented yet")
}

get_combined_name := func(e: Expr) returns Str throws Str {
    t := Token() // dummy token to call .todo_error()
    return ""
    throw t.todo_error("get_combined_name not implemented yet")
}

parse_assignment := func(lexer: Lexer, t: Token, name: Str) returns Expr throws Str {
    e := Expr()
    return e
    throw t.todo_error("parse_assignment not implemented yet")
}

parse_declaration := func(lexer: Lexer, mut_: Bool, type_name: Str) returns Expr throws Str {
    t := lexer.peek()
    e := Expr()
    return e
    throw t.todo_error("parse_declaration not implemented yet")
}

parse_statement_identifier := func(lexer: Lexer) returns Expr throws Str {
    t := lexer.peek()
    mut next_t := lexer.next()
    mut next_token_type := next_t.token_type

    switch next_token_type {
    case TokenType.LeftParen:
        return parse_primary_identifier(lexer)
    case TokenType.Dot:
        e := parse_primary_identifier(lexer)
        switch e.node_type {
        case NodeType.FCall:
            return e
        case NodeType.Identifier:
            // continue
        case:
            throw t.todo_error("a series of identifiers and dots should have been parsed as identifier or function call")
        }

        next_t = lexer.peek()
        next_token_type = next_t.token_type

        switch next_token_type {
        case TokenType.Equal:
            name := get_combined_name(e)
            return parse_assignment(lexer, t, name)
        case:
            throw t.error("While parsing a '.', this should never happen")
        }

    case TokenType.Equal:
        lexer.advance(1)
        return parse_assignment(lexer, t, t.token_str)

    case TokenType.Colon:
        next_next_t := lexer.peek_ahead(2)
        next_next_token_type := next_next_t.token_type
        identifier := t.token_str

        switch next_next_token_type {
        case TokenType.Identifier:
            type_name := next_next_t.token_str
            return parse_declaration(lexer, false, type_name)
        case TokenType.Equal:
            return parse_declaration(lexer, false, INFER_TYPE)
        case:
            throw t.error(format("Expected Type or '=' after '", identifier, " :' in statement, found '", enum_to_str(next_next_token_type), "'."))
        }

    case:
        throw t.error(format("Expected '(', ':' or '=' after identifier in statement, found '", enum_to_str(next_token_type), "'."))
    }
}

parse_statement := func(lexer: Lexer) returns Expr throws Str {
    t := lexer.peek()

    switch t.token_type {
    case TokenType.For:
        throw t.todo_error("Suggestion: use 'while' for now.\nExplanation: keyword 'for' is not supported yet,")
    case TokenType.Return:
        throw t.todo_error("parse return_statement not implemented yet")
    case TokenType.Throw:
        throw t.todo_error("parse throw_statement not implemented yet")
    case TokenType.If:
        throw t.todo_error("parse if_statement not implemented yet")
    case TokenType.While:
        throw t.todo_error("parse while_statement not implemented yet")
    case TokenType.Switch:
        throw t.todo_error("parse switch_statement not implemented yet")
    case TokenType.Mut:
        throw t.todo_error("parse mut_declaration not implemented yet")
    case TokenType.Identifier:
        throw t.todo_error("parse statement_identifier not implemented yet")
    case TokenType.Catch:
        throw t.todo_error("parse catch_statement not implemented yet")
    case:
        throw t.error(format("Expected statement, found ", enum_to_str(t.token_type)))
    }

    e := Expr()
    return e
}

parse_body := func(mut lexer: Lexer, end_token: TokenType) returns Expr throws Str {
    mut params := ExprArray()
    mut end_found := false
    start_token := lexer.peek()

    while and(
        not(end_found),
        lt(lexer.current_token, lexer.len()),
    ) {
        t := lexer.peek()
        switch t.token_type {
        case end_token:
            end_found = true

        case TokenType.Semicolon:
            lexer.advance(1)

        case:
            stmt := parse_statement(lexer)
            params.push(stmt)
        }
    }
    if end_found {
        return Expr.new_parse(NodeType.Body, start_token, params)
    }
    t := lexer.peek()
    t.error(format(loc(), "Expected the body to end with ", enum_to_str(end_token)))
}
